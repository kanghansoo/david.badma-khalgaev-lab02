{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 3 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "import json\n",
    "import re\n",
    "\n",
    "conf = SparkConf()\n",
    "\n",
    "spark = (SparkSession\n",
    "        .builder\n",
    "        .config(conf=conf)\n",
    "        .appName('test')\n",
    "        .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\r\n",
      "-rw-r--r--   3 hdfs hdfs     66.3 M 2022-01-06 18:46 /labs/slaba02/DO_record_per_line.json\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls -h /labs/slaba02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile('/labs/slaba02/DO_record_per_line.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = rdd.repartition(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, RegexTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType(fields=[\n",
    "    StructField('course_id', IntegerType()),\n",
    "    StructField('lang', StringType()),\n",
    "    StructField('name', StringType()),\n",
    "    StructField('words', ArrayType(StringType()))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json('/labs/slaba02/DO_record_per_line.json', multiLine=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---+----+--------------------+--------------+--------------------+\n",
      "|                 cat|                desc| id|lang|                name|      provider|               words|\n",
      "+--------------------+--------------------+---+----+--------------------+--------------+--------------------+\n",
      "|3/business_manage...|This course intro...|  4|  en|Accounting Cycle:...|Canvas Network|[this, course, in...|\n",
      "|              11/law|This online cours...|  5|  en|American Counter ...|Canvas Network|[this, online, co...|\n",
      "|5/computer_scienc...|This course is ta...|  6|  fr|Arithmétique: en ...|Canvas Network|[this, course, is...|\n",
      "|  14/social_sciences|We live in a digi...|  7|  en|Becoming a Dynami...|Canvas Network|[we, live, in, a,...|\n",
      "|2/biology_life_sc...|This self-paced c...|  8|  en|           Bioethics|Canvas Network|[this, self-paced...|\n",
      "+--------------------+--------------------+---+----+--------------------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexTokenizer(inputCol='desc', outputCol='words')\n",
    "wordsData = tokenizer.transform(df)\n",
    "wordsData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol='words', outputCol='rawFeatures', numFeatures=10000)\n",
    "featurizedData = hashingTF.transform(wordsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = rescaledData.select('id', 'lang', 'name', 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+--------------------+--------------------+\n",
      "| id|lang|                name|            features|\n",
      "+---+----+--------------------+--------------------+\n",
      "|  4|  en|Accounting Cycle:...|(10000,[36,42,63,...|\n",
      "|  5|  en|American Counter ...|(10000,[32,222,29...|\n",
      "|  7|  en|Becoming a Dynami...|(10000,[493,572,7...|\n",
      "|  8|  en|           Bioethics|(10000,[32,65,115...|\n",
      "|  9|  en|College Foundatio...|(10000,[56,91,268...|\n",
      "| 10|  en|Digital Literacies I|(10000,[1045,1263...|\n",
      "| 11|  en|Digital Literacie...|(10000,[87,157,57...|\n",
      "| 12|  en|Digital Tools for...|(10000,[161,164,4...|\n",
      "| 13|  en|Discover Your Val...|(10000,[26,1072,1...|\n",
      "| 14|  en|Enhancing Patient...|(10000,[63,145,23...|\n",
      "| 15|  en|Ethics and Values...|(10000,[32,65,77,...|\n",
      "| 16|  en| Exploring Chemistry|(10000,[32,273,30...|\n",
      "| 17|  en|Exploring Enginee...|(10000,[695,1420,...|\n",
      "| 18|  en|Fairy Tales: Orig...|(10000,[307,316,3...|\n",
      "| 19|  en|First Peoples to ...|(10000,[572,768,8...|\n",
      "| 20|  en| Forums for a Future|(10000,[91,273,31...|\n",
      "| 21|  en|From the Gilded A...|(10000,[148,157,1...|\n",
      "| 22|  en|Fundamentals of S...|(10000,[128,177,2...|\n",
      "| 23|  en|Hybrid Courses: B...|(10000,[91,332,52...|\n",
      "| 24|  en|International Hea...|(10000,[115,128,2...|\n",
      "+---+----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.filter(\"lang == 'en'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.createOrReplaceTempView(\"df2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT id, lang, name, rawFeatures\n",
    "from david\n",
    "where lang = 'en'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'bigint'),\n",
       " ('lang', 'string'),\n",
       " ('name', 'string'),\n",
       " ('features', 'vector')]"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def cos_dist(x, y):\n",
    "    return x.dot(y) / (x.norm(2) * y.norm(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses = df2.filter(df.id.isin([21617, 23126, 16627, 11556, 16704, 13702]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+--------------------+--------------------+\n",
      "|   id|lang|                name|            features|\n",
      "+-----+----+--------------------+--------------------+\n",
      "|11556|  es|Aprendizaje Colab...|(10000,[249,522,5...|\n",
      "|13702|  ru|Математическая эк...|(10000,[310,763,9...|\n",
      "|16627|  es|Aprende Excel: Ni...|(10000,[30,145,19...|\n",
      "|16704|  ru|Программирование ...|(10000,[381,1144,...|\n",
      "|21617|  en|Preparing for the...|(10000,[213,360,4...|\n",
      "|23126|  en|Compass - powerfu...|(10000,[87,91,96,...|\n",
      "+-----+----+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "courses.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses.createOrReplaceTempView(\"courses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = [(courses.lang == df2.lang) & (courses.id != df2.id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = courses.join(df2, cond, how='inner').select(courses.id.alias('c_id'), df2.id.alias('d_id'), courses.features.alias('v1'), df2.features.alias('v2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT c.id as c_id\n",
    "       ,d.id as d_id \n",
    "       ,c.features as v1\n",
    "       ,d.features as v2\n",
    "       ,d.name\n",
    "from courses c\n",
    "    join df2 d on\n",
    "        c.lang = d.lang\n",
    "        and c.id != d.id\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = (spark.sql(query).rdd.coalesce(12)\\\n",
    "     .map(lambda x: (int(x[0]), float(cos_dist(x[2], x[3])), int(x[1]), x[4]))\\\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType(fields=[\n",
    "    StructField('task_id', IntegerType()),\n",
    "    StructField('cos_dist', FloatType()),\n",
    "    StructField('rec_id', IntegerType()),\n",
    "    StructField('rec_name', StringType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(f, schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort(df.task_id.asc(), df.cos_dist.desc(), df.rec_name.asc(), df.rec_id.asc()).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.na.drop(subset=['cos_dist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [str(row[0]) for row in courses.select('id').take(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "for i in keys:\n",
    "    answers.append([row[0] for row in df.filter(df.task_id == i).select('rec_id').take(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = {keys[i]: answers[i] for i in range(len(keys))}\n",
    "\n",
    "with open(r\"lab02.json\", 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!hdfs dfs -put lab02.json /user/david.badma-khalgaev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\r\n",
      "drwx------   - david.badma-khalgaev david.badma-khalgaev          0 2022-04-25 03:00 /user/david.badma-khalgaev/.Trash\r\n",
      "drwxr-xr-x   - david.badma-khalgaev david.badma-khalgaev          0 2022-04-27 07:58 /user/david.badma-khalgaev/.sparkStaging\r\n",
      "-rw-r--r--   3 david.badma-khalgaev david.badma-khalgaev        179 2022-04-14 14:10 /user/david.badma-khalgaev/lab01.json\r\n",
      "-rw-r--r--   3 david.badma-khalgaev david.badma-khalgaev        457 2022-04-24 19:37 /user/david.badma-khalgaev/lab02.json\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/david.badma-khalgaev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
